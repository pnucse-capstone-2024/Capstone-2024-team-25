{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\wlsdu\\\\Desktop\\\\developer\\\\final_project\\\\topik\\\\topik-korea-data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem_generator import Problem_Generate_Model\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유형1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 바로 채점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"total_points\": 9}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_paragraph = \"초대합니다. 한 달 전에 이사를 했습니다. 그동안 집안 정리 때문에 정신이 없었는데 이제 좀 정리가 됐습니다.\" \\\n",
    "#     \"그래서 저희 집에서 (㉠). (㉡)? 그 시간이 괜찮으신지 연락 주시면 감사하겠습니다.\"\n",
    "# sample_answer1 = \"파티를 열려고 합니다.\"\n",
    "# # sample_answer2 = \"5월 17일에 오후 1시에 시간되실까요\"\n",
    "# sample_answer2 = \"음식은 양식 어떠세요\"\n",
    "# criteria = \"답안을 작성할 때는 담화의 앞뒤 내용을 잘 파악하는 것이 중요합니다.\" \\\n",
    "#         \" ㉠과 ㉡ 의 앞이나 뒤에 있는 문장들을 잘 살펴보고 내용이 자연스럽게 이어지도록 해야 합니다. \"\\\n",
    "#         \"담화의 문맥에 적합하지 않은 어휘나 문법을 사용하면 감점이 됩니다.\" \\\n",
    "#         \"불필요한 내용이 추가되어 원래의 의미를 해치는 경우 감점이 됩니다.\"\\\n",
    "#         \"철자법이 정확하지 않거나 글의 형식성, 격식성에 맞지 않으면 감점이 됩니다.\"\\\n",
    "#         \"답안에 (      ) 앞뒤의 어구를 포함해서 쓰지 않도록 주의하십시오.\"\\\n",
    "#         \"답안을 한 문장 이상으로 쓰지 않도록 주의하십시오.\"\n",
    "\n",
    "# def prompt_for_writing_type_1(paragraph=None, answers=None):\n",
    "#     if paragraph is None or answers is None:\n",
    "#         raise ValueError(\"paragraph is required\")\n",
    "#     else:\n",
    "#         sysMsg = '너는 글쓰기 평가 전문가야. 입력된 답안을 채점해줘. 빈칸별 점수 범위 0-5점. 예시: {\"total_points\": 8}'\n",
    "#         userMsg = {\"paragraph\": paragraph, \"blank1\": answers[0], \"blank2\": answers[1], \"답안 작성 방법\": criteria}\n",
    "#     return sysMsg, str(userMsg)\n",
    "\n",
    "# verbose=False\n",
    "# default_model=\"gpt-4o-mini\"\n",
    "# total_cost = 0\n",
    "# models = [default_model]\n",
    "# problem_generate_model = Problem_Generate_Model(\n",
    "#     models, use_cache=True, temperature=0.8, verbose=verbose\n",
    "# )\n",
    "\n",
    "# sysMsg, userMsg =  prompt_for_writing_type_1(sample_paragraph, [sample_answer1, sample_answer2])\n",
    "\n",
    "# problem_generate_model.request_models_responses(\n",
    "#     [\n",
    "#         SystemMessage(content=sysMsg),\n",
    "#         HumanMessage(content=userMsg),\n",
    "#     ]\n",
    "# )\n",
    "# assessment_responses = problem_generate_model.get_model_responses()\n",
    "# total_points = assessment_responses[0][1]\n",
    "# total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between text1 and text2: 0.5945091149557441\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "api_key_file = \"API_KEY/llm_api_key.json\"\n",
    "if os.path.exists(api_key_file):\n",
    "    with open(api_key_file) as f:\n",
    "        api_key = json.load(f)\n",
    "else:\n",
    "    api_key = {\n",
    "        \"OPENAI_API_KEY\": \"your_openai_api_key_here\",\n",
    "    }\n",
    "    with open(api_key_file, \"w\") as f:\n",
    "        json.dump(api_key, f)\n",
    "\n",
    "if (\n",
    "    api_key[\"OPENAI_API_KEY\"] == \"your_openai_api_key_here\"\n",
    "):\n",
    "    print(\"Please update your API keys in the API_KEY/api_key.json file\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    # openai.api_key = api_key[\"OPENAI_API_KEY\"]\n",
    "    client = OpenAI(\n",
    "    api_key=api_key[\"OPENAI_API_KEY\"]\n",
    "    )\n",
    "\n",
    "# Function to get the embedding\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    # Cosine similarity: dot_product(A, B) / (norm(A) * norm(B))\n",
    "    embedding1 = np.array(embedding1)\n",
    "    embedding2 = np.array(embedding2)\n",
    "    \n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm_a = np.linalg.norm(embedding1)\n",
    "    norm_b = np.linalg.norm(embedding2)\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# Sample texts\n",
    "text1 = \"OpenAI is an AI research lab.\"\n",
    "text2 = \"Artificial intelligence advances in the lab.\"\n",
    "\n",
    "# Get embeddings for both texts\n",
    "embedding1 = get_embedding(text1)\n",
    "embedding2 = get_embedding(text2)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(f\"Similarity score between text1 and text2: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 답변 생성 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from difflib import SequenceMatcher\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def create_openai_client():\n",
    "    api_key_file = \"API_KEY/llm_api_key.json\"\n",
    "    if os.path.exists(api_key_file):\n",
    "        with open(api_key_file) as f:\n",
    "            api_key = json.load(f)\n",
    "    else:\n",
    "        api_key = {\n",
    "            \"OPENAI_API_KEY\": \"your_openai_api_key_here\",\n",
    "        }\n",
    "        with open(api_key_file, \"w\") as f:\n",
    "            json.dump(api_key, f)\n",
    "\n",
    "    if (\n",
    "        api_key[\"OPENAI_API_KEY\"] == \"your_openai_api_key_here\"\n",
    "    ):\n",
    "        print(\"Please update your API keys in the API_KEY/api_key.json file\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        # openai.api_key = api_key[\"OPENAI_API_KEY\"]\n",
    "        client = OpenAI(\n",
    "        api_key=api_key[\"OPENAI_API_KEY\"]\n",
    "        )\n",
    "    return client\n",
    "\n",
    "# Function to get the embedding\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    # Cosine similarity: dot_product(A, B) / (norm(A) * norm(B))\n",
    "    embedding1 = np.array(embedding1)\n",
    "    embedding2 = np.array(embedding2)\n",
    "    \n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm_a = np.linalg.norm(embedding1)\n",
    "    norm_b = np.linalg.norm(embedding2)\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def cosine_similarity_using_openai_embeddings(text1, text2):\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    similarity = cosine_similarity(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "def sentence_to_tokens(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "def sequenceMatcher_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def filter_nouns(tokens):\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    nouns = [word for word, pos in tagged_tokens if pos.startswith('NN')]\n",
    "    return nouns\n",
    "\n",
    "def similarity_between_sentences(sentence1, sentence2):\n",
    "    tokens1 = sentence_to_tokens(sentence1)\n",
    "    tokens2 = sentence_to_tokens(sentence2)\n",
    "    nouns1 = filter_nouns(tokens1)\n",
    "    nouns2 = filter_nouns(tokens2)\n",
    "    similarity = 0.0\n",
    "    for noun1 in nouns1:\n",
    "        for noun2 in nouns2:\n",
    "            similarity += sequenceMatcher_similarity(noun1, noun2)\n",
    "    return similarity\n",
    "\n",
    "def bonus_point(similarity):\n",
    "    print(f\"similarity: {similarity}\")\n",
    "    bonus_point = 0\n",
    "    if similarity > 0.4 and similarity < 1.0:\n",
    "        bonus_point = 2\n",
    "    elif similarity >= 1.0:\n",
    "        bonus_point = 4\n",
    "    return bonus_point\n",
    "\n",
    "# Example usage\n",
    "sentence = \"This is an example sentence.\"\n",
    "tokens = sentence_to_tokens(sentence)\n",
    "print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer1': '작은 집들이를 하고 싶습니다', 'answer2': '그날 오후 6시에 괜찮으신가요'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userMsg: {'answer1:': '작은 집들이를 하고 싶습니다', 'answer1_guess': '파티를 열려고 합니다.', 'answer2:': '그날 오후 6시에 괜찮으신가요', 'answer2_guess': '음식은 양식 어떠세요'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer1': '하', 'answer1_guess': '하', 'answer2': '하', 'answer2_guess': '하'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'answer1': 'I want to have a small gathering.',\n",
       " 'answer1_guess': 'I am planning to hold a party.',\n",
       " 'answer2': 'Is 6 PM that day okay for you?',\n",
       " 'answer2_guess': 'How about Western food?'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: 0.5840664007390043\n",
      "similarity: 0.20967549439498678\n",
      "point_pair: [3, 1]\n",
      "Grammar answers: {'typo_in_sentence1': 'none', 'typo_in_sentence2': 'none'}\n",
      "point_pair: [3, 1]\n",
      "total_points: 4\n"
     ]
    }
   ],
   "source": [
    "sample_paragraph = \"초대합니다. 한 달 전에 이사를 했습니다. 그동안 집안 정리 때문에 정신이 없었는데 이제 좀 정리가 됐습니다.\" \\\n",
    "    \"그래서 저희 집에서 (㉠). (㉡)? 그 시간이 괜찮으신지 연락 주시면 감사하겠습니다.\"\n",
    "sample_answer1 = \"파티를 열려고 합니다.\"\n",
    "sample_answer2 = \"5월 17일에 오후 1시에 시간되실까요\"\n",
    "# sample_answer2 = \"5월 17일에 오후 1시에 시강되실까요\"\n",
    "sample_answer2 = \"음식은 양식 어떠세요\"\n",
    "# sample_answer2 = \"옴식은 양식 어떠세요\"\n",
    "criteria = \"상: 의미가 완전히 일치함, 중: 의미가 일부 일치함, 하: 의미가 일치하지 않음\"\n",
    "level_to_points = {\"상\": 5, \"중\": 3, \"하\": 1}\n",
    "\n",
    "verbose=False\n",
    "default_model=\"gpt-4o-mini\"\n",
    "total_cost = 0\n",
    "models = [default_model]\n",
    "answer_generate_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.5, verbose=verbose\n",
    ")\n",
    "\n",
    "### Generate answers\n",
    "answer_generate_model.request_models_responses(\n",
    "    [\n",
    "        # SystemMessage(content=\"너는 한국어 글쓰기 전문가야. 빈칸에 들어가야 할 말을 적합한 어휘를 사용하여 구체적으로 채워넣어줘. 예시: {'blank1': '', 'blank2': ''}\"),\n",
    "        SystemMessage(content=\"너는 한국어 전문가야. 빈칸에 들어가야 할 말을 문맥에 맞게, 구체적으로 생성해줘. 예시: {'answer1': '', 'answer2': ''}\"),\n",
    "        HumanMessage(content=f\"paragraph: {sample_paragraph}\"),\n",
    "    ]\n",
    ")\n",
    "answer_responses = answer_generate_model.get_model_responses()\n",
    "answers = answer_responses[0][1]\n",
    "answers = ast.literal_eval(answers)\n",
    "display(answers)\n",
    "\n",
    "### Assess answers based on the criteria, which is 상/중/하\n",
    "answer_assessment_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.8, verbose=verbose\n",
    ")\n",
    "\n",
    "userMsg = {\"answer1:\": answers[\"answer1\"], \"answer1_guess\": sample_answer1, \n",
    "           \"answer2:\": answers[\"answer2\"], \"answer2_guess\": sample_answer2}\n",
    "userMsg = str(userMsg)\n",
    "response_example = \"예시: {'point1': '상', 'point2': '중'}\"\n",
    "print(f\"userMsg: {userMsg}\")\n",
    "answer_assessment_model.request_models_responses(\n",
    "    [\n",
    "        # SystemMessage(content=\"정답과 비교하여 입력된 답안을 채점해줘. 의미만 유사하면 정답이야. 정답과 입력에 포함되어있는 숫자는 달라도 돼. 후하게 점수를 줘. 입력별 점수 범위 0-5점. 예시: {'total_points': 8, '채점 근거': ''}\"),\n",
    "        # SystemMessage(content=\"정답과 비교하여 입력된 답안을 채점해줘. generous하게 점수를 줘. 총점 범위 0-10점. 예시: {'total_points': 8, '채점 근거': ''}\"),\n",
    "        SystemMessage(content=f\"정답과 비교하여 입력된 답안을 채점해줘. 채점 기준: {criteria}. 예시: {response_example}\"),\n",
    "        HumanMessage(content=userMsg),\n",
    "    ]\n",
    ")\n",
    "scoring_responses = answer_assessment_model.get_model_responses()\n",
    "scoring_result = scoring_responses[0][1]\n",
    "scoring_result = ast.literal_eval(scoring_result)\n",
    "display(scoring_result)\n",
    "point_pair = [level_to_points[scoring_result[\"answer1\"]], level_to_points[scoring_result[\"answer2\"]]]\n",
    "# print(f\"scoring_result: {scoring_result}\")\n",
    "# total_points = scoring_result[\"total_points\"]\n",
    "# # total_points += 2\n",
    "# if total_points > 10:\n",
    "#     total_points = 10\n",
    "# print(f\"total_points: {total_points}\")\n",
    "\n",
    "### post-processing\n",
    "## Translate the answers to English\n",
    "translate_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.0, verbose=verbose\n",
    ")\n",
    "translate_model.request_models_responses(\n",
    "    [\n",
    "        SystemMessage(content=\"너는 번역가야. 한국어를 영어로 번역해줘. 예시: {'answer1': '', 'answer1_guess': '', 'answer2': '', 'answer2_guess': ''}\"),\n",
    "        HumanMessage(content=f\"input: {userMsg}\"),\n",
    "    ]\n",
    ")\n",
    "english_responses = translate_model.get_model_responses()\n",
    "english_answers = english_responses[0][1]\n",
    "english_answers = ast.literal_eval(english_answers)\n",
    "display(english_answers)\n",
    "\n",
    "similarity1 = cosine_similarity_using_openai_embeddings(english_answers[\"answer1\"], english_answers[\"answer1_guess\"])\n",
    "similarity2 = cosine_similarity_using_openai_embeddings(english_answers[\"answer2\"], english_answers[\"answer2_guess\"])\n",
    "\n",
    "point_pair[0] += bonus_point(similarity1)\n",
    "point_pair[1] += bonus_point(similarity2)\n",
    "if point_pair[0] > 5:\n",
    "    point_pair[0] = 5\n",
    "if point_pair[1] > 5:\n",
    "    point_pair[1] = 5\n",
    "print(f\"point_pair: {point_pair}\")\n",
    "\n",
    "### Grammar checking model\n",
    "grammar_check_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.3, verbose=verbose\n",
    ")\n",
    "grammar_check_model.request_models_responses(\n",
    "    [\n",
    "        SystemMessage(content=\"당신은 오타(typo)를 찾아내는 도우미입니다. 주어진 문장에서 문맥, 문장부호, 조사 유무는 고려하지 말고, 오직 단어의 철자가 정확한지 판단해주세요. 예시: {'typo_in_sentence1': 'none', 'typo_in_sentence2': '공뷰'}\"),\n",
    "        HumanMessage(content=f\"sentence1: {sample_answer1}, sentence2: {sample_answer2}\"),\n",
    "    ]\n",
    ")\n",
    "grammar_check_responses = grammar_check_model.get_model_responses()\n",
    "grammar_answers = grammar_check_responses[0][1]\n",
    "grammar_answers = ast.literal_eval(grammar_answers)\n",
    "grammar_answers\n",
    "print(f\"Grammar answers: {grammar_answers}\")\n",
    "if grammar_answers[\"typo_in_sentence1\"] != \"none\":\n",
    "    point_pair[0] -= 1\n",
    "if grammar_answers[\"typo_in_sentence2\"] != \"none\":\n",
    "    point_pair[1] -= 1\n",
    "total_points = sum(point_pair)\n",
    "print(f\"point_pair: {point_pair}\")\n",
    "print(f\"total_points: {total_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유형2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_criteria_2_1_1 = \"주어진 과제를 충실히 수행하였는가?\"\n",
    "assessment_criteria_2_1_2 = \"주제와 관련된 내용으로 구성하였는가?\"\n",
    "assessment_criteria_2_1_3 = \"주어진 내용을 풍부하고 다양하게 표현하였는가?\"\n",
    "assessment_criteria_2_2_1 = \"글의 구성이 명확하고 논리적인가?\"\n",
    "assessment_criteria_2_2_2 = \"글의 내용에 따라 단락 구성이 잘 이루어졌는가?\"\n",
    "assessment_criteria_2_2_3 = \"논리 전개에 도움이 되는 담화 표지를 적절하게 사용하여 조직적으로 연결하였는가?\"\n",
    "assessment_criteria_2_3_1 = \"문법과 어휘를 다양하고 풍부하게 사용하며 적절한 문법과 어휘를 선택하여 사용하였는가?\"\n",
    "assessment_criteria_2_3_2 = \"문법, 어휘, 맞춤법 등의 사용이 정확한가?\"\n",
    "assessment_criteria_2_3_3 = \"글의 목적과 기능에 따라 격식에 맞게 글을 썼는가?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_to_points_criteria_for_2_1 = {\"상\": 7/3, \"중\": 5/3, \"하\": 2/3}\n",
    "level_to_points_criteria_for_2_2 = {\"상\": 7/3, \"중\": 5/3, \"하\": 2/3}\n",
    "level_to_points_criteria_for_2_3 = {\"상\": 16/3, \"중\": 12/3, \"하\": 6/3}\n",
    "\n",
    "def assess_by_criteria(llm_model, topic, user_answer, criteria, level_to_points):\n",
    "    llm_model.request_models_responses(\n",
    "        [\n",
    "            SystemMessage(content=\"너는 주어진 기준에 따라 글을 채점해줘. 채점은 상/중/하 중 하나로. 예시: {'level': '상'}\"),\n",
    "            HumanMessage(content=f\"user_answer: {user_answer}, topic: {topic}, criteria: {criteria}\"),\n",
    "        ]\n",
    "    )\n",
    "    responses = llm_model.get_model_responses()\n",
    "    result = responses[0][1]\n",
    "    result = ast.literal_eval(result)\n",
    "    point = level_to_points[result[\"level\"]]\n",
    "    print(f\"point: {point}\")\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point: 1.6666666666666667\n",
      "point: 2.3333333333333335\n",
      "point: 1.6666666666666667\n",
      "point: 1.6666666666666667\n",
      "point: 1.6666666666666667\n",
      "point: 1.6666666666666667\n",
      "point: 4.0\n",
      "point: 5.333333333333333\n",
      "point: 5.333333333333333\n",
      "Article length: 100\n",
      "total_points: 17\n"
     ]
    }
   ],
   "source": [
    "sample_article = \"인터넷은 우리 일상에 깊숙이 자리 잡은 필수적인 도구가 되었습니다. 정보의 바다라 불리는 인터넷은 전 세계의 지식을 손쉽게 접할 수 있게 해주며, 시공간의 제약 없이 소통을 가능케 합니다. 교육, 비즈니스, 엔터테인먼트 등 다양한 분야에서 혁신을 이끌어내고 있죠. 그러나 인터넷에는 부작용도 있습니다. 개인정보 유출, 사이버 범죄, 허위정보 확산 등의 문제가 끊임없이 제기되고 있습니다. 또한 과도한 사용으로 인한 중독과 현실과의 괴리 현상도 우려됩니다. 따라서 인터넷의 장점을 최대한 활용하면서도 그 부작용을 최소화하기 위한 노력이 필요합니다. 디지털 리터러시 교육과 적절한 규제, 그리고 개인의 자제력이 요구되는 시대입니다.\"\n",
    "sample_article = \"인터넷은 좋은 점도 있고 나쁜 점도 있습니다. 좋은 점은 정보를 쉽게 찾을 수 있고 멀리 있는 사람들과 대화할 수 있다는 거에요. 그리고 온라인 쇼핑도 할 수 있어서 편리합니다. 하지만 나쁜 점도 있어요. 가짜 뉴스가 많이 퍼지고 있고, 어린이들이 나쁜 것을 보게 될 수도 있습니다. 그리고 너무 많이 사용하면 중독될 수 있어요. 그래서 인터넷을 사용할 때는 조심해야 해요. 부모님들은 아이들이 인터넷을 사용할 때 옆에 있어주는 게 좋습니다. 그리고 모든 사람들이 인터넷에서 본 정보가 진짜인지 확인해봐야 해요.\"\n",
    "sample_article = \"인터넷은 좋은 점도 있고 나쁜 점도 있습니다. 좋은 점은 정보를 쉽게 찾을 수 있고 멀리 있는 사람들과 대화할 수 있다는 거에요. 그리고 온라인 쇼핑도 할 수 있어서 편리합니다. \"\n",
    "sample_topic = '인터넷의 장단점'\n",
    "assessment_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.5, verbose=verbose\n",
    ")\n",
    "\n",
    "total_points = 0\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_1_1, level_to_points_criteria_for_2_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_1_2, level_to_points_criteria_for_2_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_1_3, level_to_points_criteria_for_2_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_2_1, level_to_points_criteria_for_2_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_2_2, level_to_points_criteria_for_2_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_2_3, level_to_points_criteria_for_2_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_3_1, level_to_points_criteria_for_2_3)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_3_2, level_to_points_criteria_for_2_3)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_2_3_3, level_to_points_criteria_for_2_3)\n",
    "\n",
    "penalty_weight = 1\n",
    "if len(sample_article) < 200:\n",
    "    penalty_weight = 2/3\n",
    "\n",
    "total_points = total_points * penalty_weight\n",
    "total_points = round(total_points)\n",
    "\n",
    "if total_points > 30:\n",
    "    total_points = 30\n",
    "print(f\"Article length: {len(sample_article)}\")\n",
    "print(f\"total_points: {total_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유형3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_criteria_3_1_1 = \"주어진 과제를 충실히 수행하였는가?\"\n",
    "assessment_criteria_3_1_2 = \"주제와 관련된 내용으로 구성하였는가?\"\n",
    "assessment_criteria_3_1_3 = \"내용을 풍부하고 다양하게 표현하였는가?\"\n",
    "assessment_criteria_3_2_1 = \"글의 구성이 명확하고 논리적인가?\"\n",
    "assessment_criteria_3_2_2 = \"중심 생각이 잘 구성되어 있는가?\"\n",
    "assessment_criteria_3_2_3 = \"논리 전개에 도움이 되는 담화 표지를 적절하게 사용하여 조직적으로 연결하였는가?\"\n",
    "assessment_criteria_3_3_1 = \"문법과 어휘를 다양하고 풍부하게 사용하며 적절한 문법과 어휘를 선택하여 사용하였는가?\"\n",
    "assessment_criteria_3_3_2 = \"문법, 어휘, 맞춤법 등의 사용이 정확한가?\"\n",
    "assessment_criteria_3_3_3 = \"글의 목적과 기능에 따라 격식에 맞게 글을 썼는가?\"\n",
    "\n",
    "level_to_points_criteria_for_3_1 = {\"상\": 12/3, \"중\": 8/3, \"하\": 4/3}\n",
    "level_to_points_criteria_for_3_2 = {\"상\": 12/3, \"중\": 8/3, \"하\": 4/3}\n",
    "level_to_points_criteria_for_3_3 = {\"상\": 26/3, \"중\": 18/3, \"하\": 10/3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point: 1.3333333333333333\n",
      "point: 1.3333333333333333\n",
      "point: 1.3333333333333333\n",
      "point: 1.3333333333333333\n",
      "point: 1.3333333333333333\n",
      "point: 1.3333333333333333\n",
      "point: 3.3333333333333335\n",
      "point: 3.3333333333333335\n",
      "point: 3.3333333333333335\n",
      "Article length: 355\n",
      "total_points: 0.0\n"
     ]
    }
   ],
   "source": [
    "sample_article = \"환경오염을 줄이는 것은 우리 세대의 가장 중요한 과제 중 하나입니다. 지구 온난화, 대기오염, 해양 플라스틱 문제 등 다양한 환경 문제가 심각해지고 있는 현 시점에서, 우리 모두가 적극적으로 행동에 나서야 할 때입니다. 먼저, 개인적 차원에서 할 수 있는 일부터 시작해야 합니다. 일회용품 사용을 줄이고 재사용 가능한 제품을 선택하는 것이 중요합니다. 예를 들어, 플라스틱 빨대 대신 금속 빨대를, 비닐봉지 대신 에코백을 사용하는 등의 작은 실천이 모여 큰 변화를 만들 수 있습니다. 또한, 에너지 절약을 위해 불필요한 전등을 끄고, 대중교통이나 자전거 이용을 늘리는 것도 효과적인 방법입니다. 기업들의 역할도 중요합니다. 생산 과정에서 발생하는 오염물질을 줄이고, 친환경 기술 개발에 투자해야 합니다. 재생 에너지 사용을 확대하고, 제품 포장을 최소화하는 등의 노력이 필요합니다. 또한, 기업의 사회적 책임을 다하기 위해 환경보호 활동에 적극적으로 참여하고, 소비자들에게 환경 친화적인 선택을 할 수 있도록 정보를 제공해야 합니다. 정부 차원에서는 강력한 환경 정책과 법규를 마련하고 시행해야 합니다. 오염 물질 배출 기준을 강화하고, 위반 시 엄중한 처벌을 해야 합니다. 또한, 친환경 기술 개발을 위한 연구비 지원, 재활용 인프라 구축, 친환경 제품 사용 촉진을 위한 세제 혜택 등 다양한 정책을 통해 환경보호를 장려해야 합니다. 교육의 중요성도 간과할 수 없습니다. 어릴 때부터 환경 보호의 중요성을 인식하고 실천할 수 있도록 학교와 가정에서 체계적인 환경 교육이 이루어져야 합니다. 이를 통해 미래 세대가 환경에 대한 책임감을 가지고 지속 가능한 발전을 이끌어갈 수 있을 것입니다. 결론적으로, 환경오염을 줄이기 위해서는 개인, 기업, 정부, 교육 기관 등 사회 전반의 협력과 노력이 필요합니다. 우리 모두가 환경 보호의 주체라는 인식을 가지고, 각자의 위치에서 할 수 있는 일들을 실천해 나간다면, 보다 깨끗하고 건강한 지구를 후대에 물려줄 수 있을 것입니다. 지금 당장 시작하는 작은 변화가 미래를 바꿀 수 있다는 믿음으로, 우리 모두 환경 보호에 동참합시다.\"\n",
    "sample_article = \"환경오염은 우리 일상에 깊숙이 자리 잡은 필수적인 도구가 되었습니다. 정보의 바다라 불리는 환경오염은 전 세계의 지식을 손쉽게 접할 수 있게 해주며, 시공간의 제약 없이 소통을 가능케 합니다. 교육, 비즈니스, 엔터테인먼트 등 다양한 분야에서 혁신을 이끌어내고 있죠. 그러나 환경오염에는 부작용도 있습니다. 개인정보 유출, 사이버 범죄, 허위정보 확산 등의 문제가 끊임없이 제기되고 있습니다. 또한 과도한 사용으로 인한 중독과 현실과의 괴리 현상도 우려됩니다. 따라서 환경오염의 장점을 최대한 활용하면서도 그 부작용을 최소화하기 위한 노력이 필요합니다. 디지털 리터러시 교육과 적절한 규제, 그리고 개인의 자제력이 요구되는 시대입니다.\"\n",
    "sample_topic = '최근 세계적으로 환경오염을 줄이기 위해 많은 노력을 기울이고 있습니다. 환경오염을 줄일 수 있는 효과적인 방법에 대해 아래의 내용을 중심으로 주장하는 글을 쓰십시오.'\n",
    "assessment_model = Problem_Generate_Model(\n",
    "    models, use_cache=True, temperature=0.5, verbose=verbose\n",
    ")\n",
    "\n",
    "total_points = 0\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_1_1, level_to_points_criteria_for_3_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_1_2, level_to_points_criteria_for_3_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_1_3, level_to_points_criteria_for_3_1)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_2_1, level_to_points_criteria_for_3_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_2_2, level_to_points_criteria_for_3_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_2_3, level_to_points_criteria_for_3_2)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_3_1, level_to_points_criteria_for_3_3)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_3_2, level_to_points_criteria_for_3_3)\n",
    "total_points += assess_by_criteria(assessment_model, sample_topic, sample_article, assessment_criteria_3_3_3, level_to_points_criteria_for_3_3)\n",
    "\n",
    "total_points = round(total_points)\n",
    "\n",
    "penalty_weight = 1\n",
    "if len(sample_article) < 400:\n",
    "    penalty_weight = 0.0\n",
    "elif len(sample_article) >= 400 and len(sample_article) < 433:\n",
    "    penalty_weight = 0.5\n",
    "elif len(sample_article) >= 433 and len(sample_article) < 466:\n",
    "    penalty_weight = 0.666\n",
    "elif len(sample_article) >= 466 and len(sample_article) < 500:\n",
    "    penalty_weight = 0.833\n",
    "elif len(sample_article) >= 500:\n",
    "    penalty_weight = 1.0\n",
    "\n",
    "total_points = total_points * penalty_weight\n",
    "\n",
    "if total_points > 50:\n",
    "    total_points = 50\n",
    "print(f\"Article length: {len(sample_article)}\")\n",
    "print(f\"total_points: {total_points}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
